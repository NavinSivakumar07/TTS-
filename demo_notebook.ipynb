{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# TTS Demo Notebook\n",
    "\n",
    "This notebook demonstrates the complete Text-to-Speech pipeline including:\n",
    "- Data loading and exploration\n",
    "- Model training with loss visualization\n",
    "- Mel-spectrogram generation and visualization\n",
    "- Audio synthesis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.data_loader import get_dataloader\n",
    "from src.model import SimpleTTS\n",
    "from src.utils import text_to_sequence\n",
    "from src import config\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Device:\", config.DEVICE)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Data Loading and Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the dataset\n",
    "dataloader = get_dataloader(config.DATA_PATH, batch_size=4, shuffle=False)\n",
    "\n",
    "# Get a sample batch\n",
    "sample_batch = next(iter(dataloader))\n",
    "input_padded, target_padded = sample_batch\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Input shape (text sequences): {input_padded.shape}\")\n",
    "print(f\"Target shape (mel-spectrograms): {target_padded.shape}\")\n",
    "print(f\"Total batches in dataset: {len(dataloader)}\")\n",
    "\n",
    "# Visualize a sample mel-spectrogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(target_padded[0].numpy(), aspect='auto', origin='lower')\n",
    "plt.title('Sample Mel-Spectrogram')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Mel Channels')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(target_padded[0].numpy().mean(axis=0))\n",
    "plt.title('Average Mel Energy Over Time')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Average Energy')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Model Training with Loss Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9520d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and training components\n",
    "device = torch.device(config.DEVICE)\n",
    "model = SimpleTTS().to(device)\n",
    "dataloader = get_dataloader(config.DATA_PATH, config.BATCH_SIZE)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "\n",
    "# Training loop for 200+ iterations\n",
    "losses = []\n",
    "iterations = 0\n",
    "target_iterations = 200\n",
    "\n",
    "print(\"Starting training for 200+ iterations...\")\n",
    "model.train()\n",
    "\n",
    "for epoch in range(100):  # Will break when we reach target iterations\n",
    "    for batch in dataloader:\n",
    "        # Move data to device\n",
    "        text_padded, mel_target = [d.to(device) for d in batch]\n",
    "        \n",
    "        # Forward pass\n",
    "        mel_pred = model(text_padded)\n",
    "        loss = criterion(mel_pred, mel_target)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.CLIP_THRESH)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Record loss\n",
    "        losses.append(loss.item())\n",
    "        iterations += 1\n",
    "        \n",
    "        # Print progress every 50 iterations\n",
    "        if iterations % 50 == 0:\n",
    "            print(f\"Iteration {iterations}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Stop when we reach target iterations\n",
    "        if iterations >= target_iterations:\n",
    "            break\n",
    "    \n",
    "    if iterations >= target_iterations:\n",
    "        break\n",
    "\n",
    "print(f\"Training completed after {iterations} iterations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d126982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss Over Iterations')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('L1 Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Plot moving average for smoother curve\n",
    "window_size = 10\n",
    "if len(losses) >= window_size:\n",
    "    moving_avg = np.convolve(losses, np.ones(window_size)/window_size, mode='valid')\n",
    "    plt.plot(range(window_size-1, len(losses)), moving_avg, 'r-', linewidth=2)\n",
    "    plt.title(f'Moving Average Loss (window={window_size})')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('L1 Loss')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial loss: {losses[0]:.4f}\")\n",
    "print(f\"Final loss: {losses[-1]:.4f}\")\n",
    "print(f\"Loss reduction: {((losses[0] - losses[-1])/losses[0]*100):.1f}%\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Mel-Spectrogram Generation and Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3785d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mel-spectrograms from sample texts\n",
    "model.eval()\n",
    "sample_texts = [\n",
    "    \"hello world\",\n",
    "    \"this is a test\",\n",
    "    \"artificial intelligence\",\n",
    "    \"text to speech synthesis\"\n",
    "]\n",
    "\n",
    "generated_mels = []\n",
    "with torch.no_grad():\n",
    "    for text in sample_texts:\n",
    "        # Convert text to sequence\n",
    "        sequence = torch.LongTensor(text_to_sequence(text)).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Generate mel-spectrogram\n",
    "        mel_output = model(sequence)\n",
    "        generated_mels.append(mel_output.squeeze(0).cpu().numpy())\n",
    "\n",
    "# Visualize generated mel-spectrograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (text, mel) in enumerate(zip(sample_texts, generated_mels)):\n",
    "    im = axes[i].imshow(mel, aspect='auto', origin='lower', cmap='viridis')\n",
    "    axes[i].set_title(f'Generated Mel: \"{text}\"')\n",
    "    axes[i].set_xlabel('Time Steps')\n",
    "    axes[i].set_ylabel('Mel Channels')\n",
    "    plt.colorbar(im, ax=axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ed3439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare generated vs ground truth\n",
    "# Get a sample from the dataset\n",
    "sample_batch = next(iter(dataloader))\n",
    "input_padded, target_padded = sample_batch\n",
    "\n",
    "# Generate prediction for the first sample\n",
    "with torch.no_grad():\n",
    "    predicted_mel = model(input_padded[:1].to(device))\n",
    "    predicted_mel = predicted_mel.squeeze(0).cpu().numpy()\n",
    "\n",
    "ground_truth_mel = target_padded[0].numpy()\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(ground_truth_mel, aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.title('Ground Truth Mel-Spectrogram')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Mel Channels')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(predicted_mel, aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.title('Generated Mel-Spectrogram')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Mel Channels')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "difference = np.abs(ground_truth_mel - predicted_mel)\n",
    "plt.imshow(difference, aspect='auto', origin='lower', cmap='hot')\n",
    "plt.title('Absolute Difference')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Mel Channels')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate metrics\n",
    "mae = np.mean(np.abs(ground_truth_mel - predicted_mel))\n",
    "mse = np.mean((ground_truth_mel - predicted_mel) ** 2)\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Audio Synthesis (Griffin-Lim Vocoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881050f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import audio processing libraries\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "def save_wav(mel_spectrogram, path):\n",
    "    \"\"\"Converts a mel-spectrogram to a WAV file using Griffin-Lim.\"\"\"\n",
    "    stft_matrix = librosa.feature.inverse.mel_to_stft(\n",
    "        mel_spectrogram,\n",
    "        sr=config.SAMPLING_RATE,\n",
    "        n_fft=config.N_FFT\n",
    "    )\n",
    "    audio = librosa.griffinlim(stft_matrix, hop_length=config.HOP_LENGTH)\n",
    "    sf.write(path, audio, config.SAMPLING_RATE)\n",
    "    return audio\n",
    "\n",
    "# Generate audio from the first generated mel-spectrogram\n",
    "test_text = \"hello world\"\n",
    "test_mel = generated_mels[0]  # From previous cell\n",
    "\n",
    "print(f\"Converting mel-spectrogram to audio for: '{test_text}'\")\n",
    "audio_path = \"demo_output.wav\"\n",
    "audio_waveform = save_wav(test_mel, audio_path)\n",
    "\n",
    "# Display audio player\n",
    "print(f\"Audio saved to: {audio_path}\")\n",
    "display(Audio(audio_waveform, rate=config.SAMPLING_RATE))\n",
    "\n",
    "# Plot the waveform\n",
    "plt.figure(figsize=(12, 4))\n",
    "time_axis = np.linspace(0, len(audio_waveform) / config.SAMPLING_RATE, len(audio_waveform))\n",
    "plt.plot(time_axis, audio_waveform)\n",
    "plt.title(f'Generated Audio Waveform: \"{test_text}\"')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Audio duration: {len(audio_waveform) / config.SAMPLING_RATE:.2f} seconds\")\n",
    "print(f\"Sample rate: {config.SAMPLING_RATE} Hz\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
